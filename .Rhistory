par(mfrow = c(2, 2))
plot(Selected_Pok.Linear)
dev.off()
plot(Selected_Pok.Linear)
# model observation
summary(Selected_Pok.Linear)
# assumption checking
par(mfrow = c(2, 2))
plot(Selected_Pok.Linear)
dev.off()
# assumption checking
par(mfrow = c(2, 2))
plot(Selected_Pok.Linear)
# full model construction
Pok.LogLinear <- glm(log(PhyscialActivity) ~ .^2, data = Pok_Grouped)
summary(Pok.LogLinear)
vif(Pok.LogLinear)
#assumption checking
par(mfrow = c(2, 2))
plot(Pok.LogLinear)
dev.off()
###linear model###
# full model construction
Pok.Linear <- glm(PhyscialActivity ~ .^2, data = Pok_Grouped)
summary(Pok.Linear)
vif(Pok.Linear)
#assumption checking
par(mfrow = c(2, 2))
plot(Pok.Linear)
dev.off()
## variable selection
final_ols <- ols_step_best_subset(Pok.Linear)
# use multiple for discovering best model
Selected_Pok.Linear <- stepAIC(Pok.Linear)
# model observation
summary(Selected_Pok.Linear)
# assumption checking
par(mfrow = c(2, 2))
plot(Selected_Pok.Linear)
dev.off()
# full model construction
Pok.LogLinear <- glm(log(PhyscialActivity) ~ .^2, data = Pok_Grouped)
summary(Pok.LogLinear)
# full model construction
Pok.Log_Linear <- glm(log(PhyscialActivity) ~ .^2, data = Pok_Grouped)
summary(Pok.Log_Linear)
vif(Pok.Log_Linear)
#assumption checking
par(mfrow = c(2, 2))
plot(Pok.Log_Linear)
dev.off()
## variable selection
# use multiple for discovering best model
final_ols <- ols_step_best_subset(Pok.LogLinear)
## variable selection
# use multiple for discovering best model
final_ols <- ols_step_best_subset(Pok.Log_Linear)
Selected_Pok.Linear <- stepAIC(Pok.Log_Linear)
# full model construction
Pok.Log_Linear <- glm(log(PhyscialActivity) ~ .^2, data = Pok_Grouped)
summary(Pok.Log_Linear)
vif(Pok.Log_Linear)
#assumption checking
par(mfrow = c(2, 2))
plot(Pok.Log_Linear)
dev.off()
## variable selection
# use multiple for discovering best model
final_ols <- ols_step_best_subset(Pok.Log_Linear)
Selected_Pok.Log_Linear <- stepAIC(Pok.Log_Linear)
# model observation
summary(Selected_Pok.Log_Linear)
# assumption checking
par(mfrow = c(2, 2))
plot(Selected_Pok.Log_Linear)
# full model construction
Pok.Linear <- glm(PhyscialActivity ~ .^2, data = Pok_Grouped)
summary(Pok.Linear)
#assumption checking
par(mfrow = c(2, 2))
plot(Pok.Linear)
dev.off()
## variable selection
final_ols <- ols_step_best_subset(Pok.Linear)
# use multiple for discovering best model
Selected_Pok.Linear <- stepAIC(Pok.Linear)
# model observation
summary(Selected_Pok.Linear)
# assumption checking
par(mfrow = c(2, 2))
plot(Selected_Pok.Linear)
# model observation
summary(Selected_Pok.Linear)
# full model construction
Pok.Log_Linear <- glm(log(PhyscialActivity) ~ .^2, data = Pok_Grouped)
summary(Pok.Log_Linear)
#assumption checking
par(mfrow = c(2, 2))
plot(Pok.Log_Linear)
dev.off()
## variable selection
# use multiple for discovering best model
final_ols <- ols_step_best_subset(Pok.Log_Linear)
# apply AIC
Selected_Pok.Log_Linear <- stepAIC(Pok.Log_Linear)
# model observation
summary(Selected_Pok.Log_Linear)
# assumption checking
par(mfrow = c(2, 2))
plot(Selected_Pok.Log_Linear)
dev.off()
Pok.Gamma <- glm(PhyscialActivity ~ .^2, family = Gamma(link="identity"),
data=Pok_Grouped)
summary(Pok.Gamma)
par(mfrow = c(2, 2))
plot(Pok.Gamma)
## variable selection
# use multiple for discovering best model
final_ols <- ols_step_best_subset(Pok.Gamma)
Seleced_Pok.Gamma <- stepAIC(Pok.Gamma)
# model observation
summary(Seleced_Pok.Gamma)
# assumption checking
par(mfrow = c(2, 2))
plot(Seleced_Pok.Gamma)
plot(Seleced_Pok.Gamma)
# full model construction
Pok.Linear <- glm(PhyscialActivity ~ .^2, family=inverse.gaussian(link="identity")
, data = Pok_Grouped)
# full model construction
Pok.Linear <- glm(PhyscialActivity ~ ., family=inverse.gaussian(link="identity")
, data = Pok_Grouped)
# full model construction
Pok.invGaussian <- glm(PhyscialActivity ~ .^2, family=inverse.gaussian(link="identity")
, data = Pok_Grouped)
# full model construction
Pok.invGaussian <- glm(PhyscialActivity ~ ., family=inverse.gaussian(link="identity")
, data = Pok_Grouped)
summary(Pok.invGaussian)
#assumption checking
par(mfrow = c(2, 2))
plot(Pok.invGaussian)
dev.off()
## variable selection
final_ols <- ols_step_best_subset(Pok.invGaussian)
# import library required
library(dplyr)
library(psych)
library(olsrr)
library(car)
####################################
###Data Observation and Cleansing###
####################################
# loading dataset
load("pokemon.Rdata")
# observe data
head(pok,3)
# primary observe of data
summary(pok)
# checking number of missing value
sum(is.na(pok))
# checking unreasonable items in age
pok_age_s0 <- pok[pok$age <0,]
pok_age_s0
#@ This dataset is really good, without error or missing value
# However, according to the article, the records where the answer of
# ATTENTION_filter1 is not "Disagree" should be filtered
pok_new <- pok[pok$ATTENTION_filter1=="Disagree",]
pok_new$ATTENTION_filter1 <- NULL
summary(pok_new)
#################################
###Preparation of Grouped data###
#################################
###convert variables into numeric values###
pok_new[,4:30] <- pok_new[,4:30] %>% mutate_if(is.factor,as.numeric)
summary(pok_new)
###Justify the grouping###
# Calculate Cronbach's Alpha
# Attitude
alpha(pok_new[7:12], check.keys=TRUE)
# steps Attitude
alpha(pok_new[13:18], check.keys=TRUE)
# Behaviour
alpha(pok_new[19:24], check.keys=TRUE)
# Pokemon Behviour
alpha(pok_new[27:29], check.keys=TRUE)
#@ Since alpha of behaviour and Pokemon behaviour are "Acceptable"
#@ we group them together
# variable grouping
Attitude <- rowMeans(pok_new[7:12])
StepAttitude <- rowMeans(pok_new[13:18])
Behaviour <- rowMeans(pok_new[19:24])
PokemonBehaviour <- rowMeans(pok_new[27:29])
# create new dataset
Pok_Grouped <- pok_new[c(4:6)]
Pok_Grouped$Attitude <- Attitude
Pok_Grouped$StepsAttitude <- StepAttitude
Pok_Grouped$PhyscialActivity <- Behaviour
Pok_Grouped$PokemonGo_AppUsage <- pok_new$app_usage_PokemonGoApp_pokemonusage1
Pok_Grouped$social_sharing <- pok_new$social_sharing
Pok_Grouped$PokemonRelate_Behaviour <- PokemonBehaviour
head(Pok_Grouped)
summary(Pok_Grouped)
########################
###Data Visualisation###
########################
# libraries required
library(ggplot2)
library(GGally)
require(foreign)
require(MASS)
require(Hmisc)
require(reshape2)
# Start plotting
ggpairs(Pok_Grouped)
boxplot(PhyscialActivity~education,
data=Pok_Grouped,
main="Different boxplots for gender",
xlab="Month Number",
ylab="Amount of Physical Activity"
)
boxplot(PhyscialActivity~Gender,
data=Pok_Grouped,
main="Different boxplots for Education Level",
xlab="Education Level",
ylab="Amount of Physical Activity"
)
dev.off()
# full model construction
Pok.invGaussian <- glm(PhyscialActivity ~ ., family=inverse.gaussian(link="identity")
, data = Pok_Grouped)
summary(Pok.invGaussian)
#assumption checking
par(mfrow = c(2, 2))
plot(Pok.invGaussian)
dev.off()
## variable selection
final_ols <- ols_step_best_subset(Pok.invGaussian)
# use multiple for discovering best model
Selected_Pok.Linear <- stepAIC(Pok.Linear)
# use multiple for discovering best model
Selected_Pok.Linear <- stepAIC(Pok.invGaussian)
# model observation
summary(Pok.invGaussian)
## variable selection
final_ols <- ols_step_best_subset(Pok.invGaussian)
# use multiple for discovering best model
Selected_Pok.invGaussian <- stepAIC(Pok.invGaussian)
# model observation
summary(Selected_Pok.invGaussian)
# use multiple for discovering best model
Selected_Pok.invGaussian <- stepAIC(Pok.invGaussian)
# model observation
summary(Selected_Pok.invGaussian)
# assumption checking
par(mfrow = c(2, 2))
plot(Selected_Pok.invGaussian)
# full model construction
Pok.invGaussian <- glm(PhyscialActivity ~ ., family=inverse.gaussian(link="log")
, data = Pok_Grouped)
summary(Pok.invGaussian)
#assumption checking
par(mfrow = c(2, 2))
plot(Pok.invGaussian)
dev.off()
## variable selection
final_ols <- ols_step_best_subset(Pok.invGaussian)
# use multiple for discovering best model
Selected_Pok.invGaussian <- stepAIC(Pok.invGaussian)
# model observation
summary(Selected_Pok.invGaussian)
# assumption checking
par(mfrow = c(2, 2))
plot(Selected_Pok.invGaussian)
# full model construction
Pok.invGaussian <- glm(PhyscialActivity ~ ., family=inverse.gaussian(link="inverse")
, data = Pok_Grouped)
summary(Pok.invGaussian)
#assumption checking
par(mfrow = c(2, 2))
plot(Pok.invGaussian)
dev.off()
## variable selection
final_ols <- ols_step_best_subset(Pok.invGaussian)
# use multiple for discovering best model
Selected_Pok.invGaussian <- stepAIC(Pok.invGaussian)
# model observation
summary(Selected_Pok.invGaussian)
# assumption checking
par(mfrow = c(2, 2))
plot(Selected_Pok.invGaussian)
# full model construction
Pok.invGaussian <- glm(PhyscialActivity ~ ., family=inverse.gaussian(link="idenitiy")
, data = Pok_Grouped)
summary(Pok.invGaussian)
# full model construction
Pok.invGaussian <- glm(PhyscialActivity ~ ., family=inverse.gaussian(link="idenitiy")
, data = Pok_Grouped)
# full model construction
Pok.invGaussian <- glm(PhyscialActivity ~ ., family=inverse.gaussian(link="identity")
, data = Pok_Grouped)
summary(Pok.invGaussian)
#assumption checking
par(mfrow = c(2, 2))
plot(Pok.invGaussian)
dev.off()
## variable selection
final_ols <- ols_step_best_subset(Pok.invGaussian)
# use multiple for discovering best model
Selected_Pok.invGaussian <- stepAIC(Pok.invGaussian)
# model observation
summary(Selected_Pok.invGaussian)
# assumption checking
par(mfrow = c(2, 2))
# use multiple for discovering best model
Selected_Pok.invGaussian <- stepAIC(Pok.invGaussian)
# model observation
summary(Selected_Pok.invGaussian)
# assumption checking
par(mfrow = c(2, 2))
plot(Selected_Pok.invGaussian)
# full model construction
Pok.invGaussian <- glm(log(PhyscialActivity) ~ ., family=inverse.gaussian(link="identity")
, data = Pok_Grouped)
# full model construction
Pok.Log_Linear <- glm(log10(PhyscialActivity) ~ .^2, data = Pok_Grouped)
summary(Pok.Log_Linear)
#assumption checking
par(mfrow = c(2, 2))
plot(Pok.Log_Linear)
dev.off()
## variable selection
# use multiple for discovering best model
final_ols <- ols_step_best_subset(Pok.Log_Linear)
# apply AIC
Selected_Pok.Log_Linear <- stepAIC(Pok.Log_Linear)
# model observation
summary(Selected_Pok.Log_Linear)
# import library required
library(dplyr)
library(psych)
library(olsrr)
library(car)
# loading dataset
load("pokemon.Rdata")
# observe data
head(pok,3)
# primary observe of data
summary(pok)
# checking number of missing value
sum(is.na(pok))
# checking unreasonable items in age
pok_age_s0 <- pok[pok$age <0,]
pok_age_s0
#@ This dataset is really good, without error or missing value
# However, according to the article, the records where the answer of
# ATTENTION_filter1 is not "Disagree" should be filtered
pok_new <- pok[pok$ATTENTION_filter1=="Disagree",]
pok_new$ATTENTION_filter1 <- NULL
summary(pok_new)
#################################
###Preparation of Grouped data###
#################################
###convert variables into numeric values###
pok_new[,4:30] <- pok_new[,4:30] %>% mutate_if(is.factor,as.numeric)
summary(pok_new)
###Justify the grouping###
# Calculate Cronbach's Alpha
# Attitude
alpha(pok_new[7:12], check.keys=TRUE)
# steps Attitude
alpha(pok_new[13:18], check.keys=TRUE)
# Behaviour
alpha(pok_new[19:24], check.keys=TRUE)
# Pokemon Behviour
alpha(pok_new[27:29], check.keys=TRUE)
#@ Since alpha of behaviour and Pokemon behaviour are "Acceptable"
#@ we group them together
# variable grouping
Attitude <- rowMeans(pok_new[7:12])
StepAttitude <- rowMeans(pok_new[13:18])
Behaviour <- rowMeans(pok_new[19:24])
PokemonBehaviour <- rowMeans(pok_new[27:29])
# create new dataset
Pok_Grouped <- pok_new[c(4:6)]
Pok_Grouped$Attitude <- Attitude
Pok_Grouped$StepsAttitude <- StepAttitude
Pok_Grouped$PhyscialActivity <- Behaviour
Pok_Grouped$PokemonGo_AppUsage <- pok_new$app_usage_PokemonGoApp_pokemonusage1
Pok_Grouped$social_sharing <- pok_new$social_sharing
Pok_Grouped$PokemonRelate_Behaviour <- PokemonBehaviour
head(Pok_Grouped)
summary(Pok_Grouped)
########################
###Data Visualisation###
########################
# libraries required
library(ggplot2)
library(GGally)
require(foreign)
require(MASS)
require(Hmisc)
require(reshape2)
# Start plotting
ggpairs(Pok_Grouped)
boxplot(PhyscialActivity~education,
data=Pok_Grouped,
main="Different boxplots for gender",
xlab="Month Number",
ylab="Amount of Physical Activity"
)
boxplot(PhyscialActivity~Gender,
data=Pok_Grouped,
main="Different boxplots for Education Level",
xlab="Education Level",
ylab="Amount of Physical Activity"
)
dev.off()
# full model construction
Pok.Log_Linear <- glm(log10(PhyscialActivity) ~ .^2, data = Pok_Grouped)
summary(Pok.Log_Linear)
#assumption checking
par(mfrow = c(2, 2))
plot(Pok.Log_Linear)
dev.off()
## variable selection
# use multiple for discovering best model
final_ols <- ols_step_best_subset(Pok.Log_Linear)
# apply AIC
Selected_Pok.Log_Linear <- stepAIC(Pok.Log_Linear)
# model observation
summary(Selected_Pok.Log_Linear)
# assumption checking
par(mfrow = c(2, 2))
plot(Selected_Pok.Log_Linear)
dev.off()
plot(Selected_Pok.Log_Linear)
dev.off()
# full model construction
Pok.Log_Linear <- glm(log10(PhyscialActivity) ~ .^2, data = Pok_Grouped)
summary(Pok.Log_Linear)
#assumption checking
par(mfrow = c(2, 2))
plot(Pok.Log_Linear)
dev.off()
## variable selection
# use multiple for discovering best model
final_ols <- ols_step_best_subset(Pok.Log_Linear)
# apply AIC
Selected_Pok.Log_Linear <- stepAIC(Pok.Log_Linear)
# model observation
summary(Selected_Pok.Log_Linear)
# assumption checking
par(mfrow = c(2, 2))
plot(Selected_Pok.Log_Linear)
dev.off()
final_ols
# full model construction
Pok.Log_Linear <- glm(log10(PhyscialActivity) ~ .^2, data = Pok_Grouped)
summary(Pok.Log_Linear)
#assumption checking
par(mfrow = c(2, 2))
plot(Pok.Log_Linear)
## variable selection
# use multiple for discovering best model
final_ols <- ols_step_best_subset(Pok.Log_Linear)
# model observation
summary(Selected_Pok.Log_Linear)
# assumption checking
par(mfrow = c(2, 2))
plot(Selected_Pok.Log_Linear)
dev.off()
# import library required
library(dplyr)
library(psych)
library(olsrr)
library(car)
####################################
###Data Observation and Cleansing###
####################################
# loading dataset
load("pokemon.Rdata")
# observe data
head(pok,3)
# primary observe of data
summary(pok)
# checking number of missing value
sum(is.na(pok))
# checking unreasonable items in age
pok_age_s0 <- pok[pok$age <0,]
pok_age_s0
#@ This dataset is really good, without error or missing value
# However, according to the article, the records where the answer of
# ATTENTION_filter1 is not "Disagree" should be filtered
pok_new <- pok[pok$ATTENTION_filter1=="Disagree",]
pok_new$ATTENTION_filter1 <- NULL
summary(pok_new)
#################################
###Preparation of Grouped data###
#################################
###convert variables into numeric values###
pok_new[,4:30] <- pok_new[,4:30] %>% mutate_if(is.factor,as.numeric)
summary(pok_new)
# Calculate Cronbach's Alpha
## Attitude
alpha(pok_new[7:12], check.keys=TRUE)
## steps Attitude
alpha(pok_new[13:18], check.keys=TRUE)
# Physical Behaviour
alpha(pok_new[19:24], check.keys=TRUE)
# Pokemon Behviour
alpha(pok_new[27:29], check.keys=TRUE)
